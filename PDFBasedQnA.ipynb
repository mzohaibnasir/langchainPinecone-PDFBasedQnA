{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQuSVcLyDc0n0SDIu2JtQr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mzohaibnasir/langchainPinecone-PDFBasedQnA/blob/main/PDFBasedQnA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "eCC232gMrD9q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# VECTOR DATABASE\n",
        "\n",
        "is a database for storing high dimensional vector such as word embeddings and image embeddings.\n",
        "A vector database stores pieces of information as vectors. Vector databases cluster related items together, enabling similarity searches and the construction of powerful AI models.\n",
        "\n",
        "# How do vector databases work?\n",
        "Each vector in a vector database corresponds to an object or item, whether that is a word, an image, a video, a movie, a document, or any other piece of data. These vectors are likely to be lengthy and complex, expressing the location of each object along dozens or even hundreds of dimensions.\n",
        "\n",
        "For example, a vector database of movies may locate movies along dimensions like running time, genre, year released, parental guidance rating, number of actors in common, number of viewers in common, and so on. If these vectors are created accurately, then similar movies are likely to end up clustered together in the vector database.\n",
        "\n",
        "# How are vector databases used?\n",
        "Similarity and semantic searches: Vector databases allow applications to connect pertinent items together. Vectors that are clustered together are similar and likely relevant to each other. This can help users search for relevant information (e.g. an image search), but it also helps applications:\n",
        "Recommend similar products\n",
        "Suggest songs, movies, or shows\n",
        "Suggest images or video\n",
        "Machine learning and deep learning: The ability to connect relevant items of information makes it possible to construct machine learning (and deep learning) models that can do complex cognitive tasks.\n",
        "Large language models (LLMs) and generative AI: LLMs, like that on which ChatGPT and Bard are built, rely on the contextual analysis of text made possible by vector databases. By associating words, sentences, and ideas with each other, LLMs can understand natural human language and even generate text.\n",
        "To summarize: Vector databases work at scale, work quickly, and are more cost-effective than querying machine learning models without them.\n",
        "\n",
        "\n",
        "\n",
        "# Embedding generation\n",
        "\n",
        "## non dl (frequency based)\n",
        "\n",
        "1. BOW(docmat)\n",
        "2. TF-IDF\n",
        "3. n-gram\n",
        "4. One hot encoding\n",
        "5. integer encoding\n",
        "\n",
        "## issues with non-dl\n",
        "\n",
        "### for One hot encoding & integer encoding\n",
        "\n",
        "1. sparse matrix(too many zeroes)\n",
        "2. no context\n",
        "\n",
        "### for BOW(docmat), TF-IDF & n-gram\n",
        "\n",
        "1. we create encoding using vocabularly\n",
        "2. still no context\n",
        "3. frequency based\n",
        "\n",
        "## with dl\n",
        "\n",
        "1. word2vec\n",
        "2. fast text\n",
        "3. ELMO\n",
        "4. BERT\n",
        "5. Glove(matrix factorization)\n",
        "\n",
        "### benefits\n",
        "\n",
        "1. creating dense vector\n",
        "2. context-full\n",
        "\n",
        "## WORD2VEC\n",
        "\n",
        "# `based on features i.e. king has features`\n",
        "\n",
        "we pass features into NN and we get embedding vector\n",
        "\n",
        "# Vector databases store embeddings. it indexes and store embeddings for faster retrieval and similarity search.\n",
        "\n",
        "1. are used in searching\n",
        "2. clustering where text strings are grouped by similarity\n",
        "3. Recommendation: related items are recommended\n",
        "4. classification\n"
      ],
      "metadata": {
        "id": "OivSdGFkxbXE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SzzRrQeGyqkb"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ib_07YNvyuMR"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Pinecone Vector DB"
      ],
      "metadata": {
        "id": "LrLVm4Q2yuUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install langchain\n",
        "! pip install pinecone-client\n",
        "! pip install openai\n",
        "! pip install tiktoken\n",
        "! pip install pypdf\n",
        "! pip install -U langchain_pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJaxwnhyy0tD",
        "outputId": "6332b395-89e1-4ae6-bea4-de0434630cc0"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.16)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.33)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.45)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.49)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.10/dist-packages (3.2.2)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.2.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.11.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.7)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.23.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.2.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.11.0)\n",
            "Requirement already satisfied: langchain_pinecone in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.40 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (0.1.45)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (1.25.2)\n",
            "Requirement already satisfied: pinecone-client<4.0.0,>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (3.2.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.40->langchain_pinecone) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.40->langchain_pinecone) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.40->langchain_pinecone) (0.1.49)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.40->langchain_pinecone) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.40->langchain_pinecone) (2.7.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.40->langchain_pinecone) (8.2.3)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<4.0.0,>=3.2.2->langchain_pinecone) (2024.2.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<4.0.0,>=3.2.2->langchain_pinecone) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<4.0.0,>=3.2.2->langchain_pinecone) (4.11.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<4.0.0,>=3.2.2->langchain_pinecone) (2.0.7)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.40->langchain_pinecone) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.40->langchain_pinecone) (3.10.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.40->langchain_pinecone) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.40->langchain_pinecone) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.40->langchain_pinecone) (2.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.40->langchain_pinecone) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.40->langchain_pinecone) (3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "# from langchain.vectorstores import Pinecone\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "import os"
      ],
      "metadata": {
        "id": "Bz9GWKLJy1ss"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "PINECONE_API_KEY = userdata.get(\"PINECONE_API_KEY\")\n",
        "\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n",
        "\n",
        "\n",
        "# OPENAIAPIKEY,PINECONEAPIKEY"
      ],
      "metadata": {
        "id": "56ywTtO1zfWv"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we'll collect data from pdfs and convert it into embeddings"
      ],
      "metadata": {
        "id": "AxWpZ7HsI2bo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## perpare data"
      ],
      "metadata": {
        "id": "UQHd4PgRQ6uS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir pdfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aNVPAW9y1u3",
        "outputId": "e39d0686-7aca-441b-aedb-d9ed9e94295c"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘pdfs’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFDirectoryLoader(\"pdfs\")\n",
        "loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMwcCYHUIxAP",
        "outputId": "864ef78f-3aa7-470a-93c9-74b743966a9c"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.document_loaders.pdf.PyPDFDirectoryLoader at 0x7c57b7064df0>"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = loader.load()\n",
        "len(data), data[0], data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOeeDxu7y1xH",
        "outputId": "57c8894a-d333-4bfd-cde4-81599c287cfa"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 25 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 27 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 44 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 273 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 284 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 408 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 432 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 915 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 944 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1180 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1355 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1562 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1907 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1911 0 (offset 0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(504,\n",
              " Document(page_content='MANNINGFrançois CholletSECOND EDITION', metadata={'source': 'pdfs/Deep Learning with Python.pdf', 'page': 0}),\n",
              " Document(page_content='Deep Learning with Python', metadata={'source': 'pdfs/Deep Learning with Python.pdf', 'page': 1}))"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3FWfg9kcy1zZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization : dividing data into chunks"
      ],
      "metadata": {
        "id": "6yWIktVTQ-mu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "But what occurs when you present these models with a document that exceeds their context window? This is where a clever strategy known as \"chunking\" comes into play. Chunking involves dividing the document into smaller, more manageable sections that fit comfortably within the context window of the large language model.\n",
        "\n",
        "Langchain provides users with a range of chunking techniques to choose from. However, among these options, the RecursiveCharacterTextSplitter emerges as the favored and strongly recommended method.\n",
        "\n",
        "The RecursiveCharacterTextSplitter takes a large text and splits it based on a specified chunk size. It does this by using a set of characters. The default characters provided to it are [\"\\n\\n\", \"\\n\", \" \", \"\"].\n",
        "\n",
        "\n",
        "`How the text is split: by list of characters`\n",
        "____________________\n",
        "`How the chunk size is measured: by number of characters`\n",
        "______\n",
        "`trying to keep paragraphs, then sentences,then words`\n",
        "\n",
        "________\n",
        "\n",
        "Important parameters to know here are chunkSize and chunkOverlap. chunkSize controls the max size (in terms of number of characters) of the final documents. chunkOverlap specifies how much overlap there should be between chunks. This is often helpful to make sure that the text isn't split weirdly."
      ],
      "metadata": {
        "id": "Ys7Aj0oVTpja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_demo = \"\"\"Hi.\\n\\nI'm Harrison.\\n\\nHow? Are? You?\\nOkay then f f f f.\n",
        "This is a weird text to write, but gotta test the splittingggg some how.\\n\\n\n",
        "Bye!\\n\\n-H.\"\"\"\n",
        "\n",
        "\n",
        "text_splitter_demo = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 10,\n",
        "    chunk_overlap = 1\n",
        "\n",
        "\n",
        ")\n",
        "texts_demo = text_splitter_demo.split_text(text_demo)\n",
        "\n",
        "print(len(texts_demo))\n",
        "print(texts_demo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlgo1KR7y124",
        "outputId": "a5ff4c2d-f25e-4ce2-b698-79c31f1a7cfe"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n",
            "['Hi.', \"I'm\", 'Harrison.', 'How? Are?', 'You?', 'Okay then', 'f f f f.', 'This is a', 'weird', 'text to', 'write,', 'but gotta', 'test the', 'splitting', 'gggg', 'some how.', 'Bye!', '-H.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 500,\n",
        "    chunk_overlap = 20\n",
        "\n",
        ")\n",
        "text_splitter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPTURn64y11G",
        "outputId": "191dfeae-e068-4fd1-eca6-30363cf0a031"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_text_splitters.character.RecursiveCharacterTextSplitter at 0x7c57b7067a60>"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks = text_splitter.split_documents(data)\n",
        "len(text_chunks), text_chunks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmxfts6vsWaf",
        "outputId": "835a2817-a5af-4535-efab-799d7e64d0f5"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2755,\n",
              " Document(page_content='MANNINGFrançois CholletSECOND EDITION', metadata={'source': 'pdfs/Deep Learning with Python.pdf', 'page': 0}))"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_chunks[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJCbEESuy14n",
        "outputId": "cef066c8-4e79-4401-d35c-713dd08ba532"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MANNINGFrançois CholletSECOND EDITION\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_chunks[30].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0aJB9xJuVoz",
        "outputId": "680da5e0-35aa-43bd-da97-fe071de0e766"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for sequence generation 366IHow do you generate sequence data? 367The importance of the sampling strategy 368IImplementing text generation with Keras 369IA text-generation callback with variable-temperature sampling 372IWrapping up 37612.2 DeepDream 376Implementing DeepDream in Keras 377IWrapping up 38312.3 Neural style transfer 383The content loss 384IThe style loss 384INeural style transfer in Keras 385IWrapping up 39112.4 Generating images with variational autoencoders 391Sampling from\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create openai embdding class's objects"
      ],
      "metadata": {
        "id": "MoUuM4VKzqeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from openai import OpenAI\n",
        "# client = OpenAI(\n",
        "#     api_key=OPENAIAPIKEY\n",
        "# )\n",
        "\n",
        "# client"
      ],
      "metadata": {
        "id": "FPTQKXQIxTi1"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_openai import OpenAIEmbeddings\n",
        "embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "# embedding"
      ],
      "metadata": {
        "id": "vFXnQpVXxUEI"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embedding.embed_query(\n",
        "    \"how are you\"\n",
        ")) # len of embedding vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVUhFkNcxUGg",
        "outputId": "db507d02-1175-4eda-ef71-4b51cc998d2f"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1536"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import pinecone"
      ],
      "metadata": {
        "id": "HDmfkLx92gjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### we'll create embedding for each text chunk\n"
      ],
      "metadata": {
        "id": "J19xSictRpnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "pinecone is running on cloud so\n",
        "\n",
        "\n",
        "\n",
        "The PineconeVectorStore class provided by LangChain can be used to interact\n",
        "with Pinecone indexes. It’s important to remember that you must have an\n",
        "existing Pinecone index before you can create a PineconeVectorStore object.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "# vectorstore = PineconeVectorStore(\n",
        "#     # pinecone_api_key= PINECONE_API_KEY,\n",
        "#     index_name=\"testing\",\n",
        "#     embedding=embedding)\n",
        "\n",
        "# vectorstore"
      ],
      "metadata": {
        "id": "vaEHYmkR1A3l"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "The from_documents and from_texts methods of LangChain’s PineconeVectorStore class\n",
        " add records to a Pinecone index and return a PineconeVectorStore object.\n",
        "\n",
        "The from_documents method accepts a list of LangChain’s Document class objects,\n",
        "which can be created using LangChain’s CharacterTextSplitter class. The\n",
        "from_texts method accepts a list of strings. Similarly to above, you must\n",
        "provide the name of an existing Pinecone index and an Embeddings object.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "index_name = 'testing'\n",
        "\n",
        "# vectorstore_from_docs = PineconeVectorStore.from_documents(\n",
        "#         text_chunks,\n",
        "#         index_name=index_name,\n",
        "#         embedding=embedding,\n",
        "#     )\n",
        "# vectorstore_from_docs"
      ],
      "metadata": {
        "id": "cQgScyH41A6A"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorstore_from_texts = PineconeVectorStore.from_texts(\n",
        "#         [t.page_content for t in text_chunks],\n",
        "#         index_name=index_name,\n",
        "#         embedding=embedding,\n",
        "#     )\n",
        "# vectorstore_from_texts"
      ],
      "metadata": {
        "id": "Q5xszqaCamZ_"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch = PineconeVectorStore.from_texts(\n",
        "        [t.page_content for t in text_chunks],\n",
        "        index_name=index_name,\n",
        "        embedding=embedding,\n",
        "    )\n",
        "docsearch # you can see all embedings on 'testing' index on pinecone.io too"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea_zL6sSouE4",
        "outputId": "0e23811d-0653-4702-c93b-80e6582a5790"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x7c579c368850>"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### doing similarity search"
      ],
      "metadata": {
        "id": "NPr2oVv5quR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query =\" what's best ML model?\""
      ],
      "metadata": {
        "id": "h9CNFusq1A79"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = docsearch.similarity_search(query)\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDHjfQUJxULP",
        "outputId": "712f9ea0-368f-4997-93de-76ac8e758673"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='the model to make predictions'),\n",
              " Document(page_content='a model that has statistical power, the question becomes, is yourmodel sufficiently powerful? Does it have enough layers and parameters to properlymodel the problem at hand? For instance, a logistic regression model has statisticalpower on MNIST but wouldn’t be sufficient to solve the problem well. Remember thatthe universal tension in machine learning is between optimization and generalization.The ideal model is one that stands right at the border between underfitting and over-fitting, between'),\n",
              " Document(page_content='to develop a small model that is capable of beating asimple baseline. At this stage, these are the three most important things you should focus on:\\x83Feature engineering—Filter out uninformative features (feature selection) and useyour knowledge of the problem to develop new features that are likely to be useful.\\x83Selecting the correct architecture priors—What type of model architecture will youuse? A densely connected network, a convnet, a recurrent neural network, aTransformer? Is deep learning'),\n",
              " Document(page_content='if youjust need something that works okay. In this section, we’ll go beyond “works okay” to“works great and wins machine learning competitions” via a set of must-know tech-niques for building state-of-the-art deep learning models.13.1.1 Hyperparameter optimizationWhen building a deep learning model, you have to make many seemingly arbitrarydecisions: How many layers should you stack? How many units or filters should go ineach layer? Should you use relu as activation, or a different function?')]"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm=OpenAI()"
      ],
      "metadata": {
        "id": "DL4whYPkxUNg"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch.as_retriever()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM9eGF8AtVHQ",
        "outputId": "77c659bf-d2a4-4ce5-eb8d-5b16c4bbcf27"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['PineconeVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x7c579c368850>)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(  # responsible for question answer\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=docsearch.as_retriever()   # docsearch is where all embeddings are stored\n",
        ")\n",
        "# qa"
      ],
      "metadata": {
        "id": "cYLe4JlQrdpE"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "mulyWqRUrdsK",
        "outputId": "9a1d556a-edec-46db-916f-738a02bb92c1"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The best ML model would be one that has enough layers and parameters to properly model the problem at hand, and stands at the border between underfitting and overfitting. Additionally, it should have well-selected features, the correct architecture priors, and optimal hyperparameters.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### to make a small QnA system(PDF based)\n",
        "\n",
        "we'll ask from PDF"
      ],
      "metadata": {
        "id": "XZ9_hsFutlnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "while True:\n",
        "  user_input = input(f\"Input Prompt: \")\n",
        "  if user_input == 'exit':\n",
        "    print(';Exiting')\n",
        "    sys.exit()\n",
        "  if user_input == \"\":\n",
        "    continue\n",
        "  result = qa.invoke({\n",
        "      'query': user_input\n",
        "  })\n",
        "  print(f\"Answer:{result['result']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "hSwsuKSxrduM",
        "outputId": "0c87c73e-86f9-41fd-d48b-10e65c94dc51"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Prompt: authors of this book?\n",
            "Answer: The authors of this book are open source developers at Hugging Face, including the creator of the Transformers library.\n",
            "Input Prompt: name them\n",
            "Answer: I am sorry, I do not have enough context to answer this question. The context is related to creating a second model that returns something, but I am not able to determine who or what should be named.\n",
            "Input Prompt: name authors of this book\n",
            "Answer: Lewis, Leandro, and Thomas\n",
            "Input Prompt: exit\n",
            ";Exiting\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MAdDItUbrdwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KqxwSLY9rd0C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}